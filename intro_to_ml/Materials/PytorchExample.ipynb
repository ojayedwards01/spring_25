{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjxlfBhDhCPc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "id": "WHREC4d0hJP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # First convolutional layer: 3 input channels (RGB) -> 32 output channels\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        # Second convolutional layer: 32 -> 64 channels\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        # Max pooling layer to reduce spatial dimensions by a factor of 2\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # Fully connected layers\n",
        "        # After two pooling operations, the 32x32 image becomes 8x8 (32 -> 16 -> 8)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)  # CIFAR10 has 10 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # Apply conv1, relu, then pool\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # Apply conv2, relu, then pool\n",
        "        x = x.view(-1, 64 * 8 * 8)            # Flatten the tensor for the fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Mlg2pjW4iFz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN().to(device)\n",
        "for name, parameter in model.named_parameters():\n",
        "  print(name)"
      ],
      "metadata": {
        "id": "_NreczGxlz7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomLinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(CustomLinear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        # Create weight and bias as learnable parameters\n",
        "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
        "        self.bias = nn.Parameter(torch.Tensor(out_features))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        # Initialize weights with Kaiming uniform initialization\n",
        "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
        "        # Calculate bias bounds and initialize uniformly\n",
        "        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
        "        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
        "        nn.init.uniform_(self.bias, -bound, bound)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Perform the linear transformation: input * weight^T + bias\n",
        "        return F.linear(input, self.weight, self.bias)"
      ],
      "metadata": {
        "id": "izR8lBqImDtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomCNN, self).__init__()\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)  # RGB -> 32 channels\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) # 32 -> 64 channels\n",
        "        # Max pooling layer to downsample by a factor of 2\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # Fully connected layers using our CustomLinear layer.\n",
        "        # After two poolings, a 32x32 image becomes 8x8.\n",
        "        self.fc1 = CustomLinear(64 * 8 * 8, 512)\n",
        "        self.fc2 = CustomLinear(512, 10)  # CIFAR10 has 10 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # Conv1 -> ReLU -> Pool\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # Conv2 -> ReLU -> Pool\n",
        "        x = x.view(-1, 64 * 8 * 8)            # Flatten the tensor for fully connected layers\n",
        "        x = F.relu(self.fc1(x))               # CustomLinear layer 1 with ReLU activation\n",
        "        x = self.fc2(x)                       # CustomLinear layer 2 (output layer)\n",
        "        return x"
      ],
      "metadata": {
        "id": "JNAg9rKQmkkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_model = CustomCNN().to(device)\n",
        "for name, module in custom_model.named_modules():\n",
        "  print(module)"
      ],
      "metadata": {
        "id": "HeNNthR2mq_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cifar10_dataloaders(batch_size=64):\n",
        "  # Data transforms including normalization\n",
        "  transform = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "  ])\n",
        "\n",
        "  # Download and load the training and test datasets\n",
        "  trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "  testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "  trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "  testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "  return trainloader, testloader"
      ],
      "metadata": {
        "id": "tLiIMm4JnXg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "ax55zt_ons1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, trainloader, criterion, optimizer, device):\n",
        "  model.train()  # Set model to training mode\n",
        "  for inputs, labels in trainloader:\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "      optimizer.zero_grad()       # Zero the gradients\n",
        "      outputs = model(inputs)     # Forward pass\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()             # Backward pass\n",
        "      optimizer.step()            # Update parameters"
      ],
      "metadata": {
        "id": "1pa7UI4qpCjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(model, testloader, criterion, device):\n",
        "  model.eval()  # Set model to evaluation mode\n",
        "  total_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for inputs, labels in testloader:\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          total_loss += loss.item() * inputs.size(0)  # Accumulate loss over batch\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "  avg_loss = total_loss / total\n",
        "  accuracy = 100 * correct / total\n",
        "  print(f'Evaluation loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
        "  return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "z2dFj1MepGPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader, testloader = get_cifar10_dataloaders()\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "    train(model, trainloader, criterion, optimizer, device)\n",
        "    eval(model, testloader, criterion, device)"
      ],
      "metadata": {
        "id": "lXUyQn1ZpMYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_vit = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "def get_cifar10_dataloaders_vit(batch_size=64):\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_vit)\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_vit)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "    return trainloader, testloader\n",
        "\n",
        "# Load a pretrained ViT model (e.g., vit_b_16) and replace its head for 10 CIFAR10 classes.\n",
        "vit_model = models.vit_b_16(pretrained=True)\n",
        "# vit_model.head = nn.Linear(vit_model.head.in_features, 10)\n",
        "vit_model = vit_model.to(device)\n",
        "\n",
        "\"\"\"\n",
        "print(\"ViT Model parameters:\")\n",
        "for name, parameter in vit_model.named_parameters():\n",
        "    print(name)\n",
        "\"\"\"\n",
        "\n",
        "vit_criterion = nn.CrossEntropyLoss()\n",
        "vit_optimizer = optim.Adam(vit_model.parameters(), lr=0.001)\n",
        "\n",
        "vit_trainloader, vit_testloader = get_cifar10_dataloaders_vit()\n",
        "\n",
        "print(\"Finetuning ViT model on CIFAR10\")\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'ViT Epoch {epoch + 1}/{num_epochs}')\n",
        "    train(vit_model, vit_trainloader, vit_criterion, vit_optimizer, device)\n",
        "    eval(vit_model, vit_testloader, vit_criterion, device)"
      ],
      "metadata": {
        "id": "W53RU0i0_sIN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}